{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "import uuid\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings, Collection\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "from typing import Any, Callable, Literal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n\\nTask 1.5: get chroma working on basic example\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "\n",
    "Task 1.5: get chroma working on basic example\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def get_embeddings(docs: Documents, model=\"text-embedding-3-large\"):\n",
    "   return [result.embedding for result in openai_client.embeddings.create(input=docs, model=model).data]\n",
    "\n",
    "class OpenAIEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        return get_embeddings(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\".chroma\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"test\", embedding_function=OpenAIEmbeddingFunction())\n",
    "\n",
    "docs = [\"one\", \"two\", \"The major scale is just a rotation of the minor scale\"]\n",
    "collection.add(\n",
    "    ids = [str(uuid.uuid4()) for _ in docs],\n",
    "    documents = docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['b5f4ca23-8969-4e88-a7c1-310962e89dd7',\n",
       "   '6e319cd1-99a7-427f-8ef8-d7f587061a07',\n",
       "   'cfe0e2a4-370d-44a4-891d-815e3030cc1d',\n",
       "   '37672081-35a4-46ff-aadf-a7944a94c942',\n",
       "   'd464493d-81d0-4cf8-9d6d-0c667fe1e6f2',\n",
       "   '1bc3b501-08bf-4bd8-9dd1-97c243921253',\n",
       "   '5b34d9be-b561-48f2-bf4c-4474ee6c8ca3',\n",
       "   'fa876d71-d245-4664-9466-f1587a259bd8',\n",
       "   '53810a72-8faf-4503-b422-35f22d6de89c',\n",
       "   'de182245-e637-4ed9-ad0d-f75e3d31904a']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['The major scale is just a rotation of the minor scale',\n",
       "   'The major scale is just a rotation of the minor scale',\n",
       "   'The major scale is just a rotation of the minor scale',\n",
       "   'The major scale is just a rotation of the minor scale',\n",
       "   'one',\n",
       "   'one',\n",
       "   'one',\n",
       "   'one',\n",
       "   'two',\n",
       "   'two']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'distances': [[0.8220085367820464,\n",
       "   0.8220085367820464,\n",
       "   0.8220085367820464,\n",
       "   0.8220085367820464,\n",
       "   1.757888130255237,\n",
       "   1.757888130255237,\n",
       "   1.757888130255237,\n",
       "   1.757888130255237,\n",
       "   1.7741536874723056,\n",
       "   1.7741536874723056]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(query_texts=[\"What is your perspective on the major scale?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n\\nTask : Create pipeline to add ml-ops-org content to Chroma vector database\\n    - choose:\\n        - embedding function \\n        - distance metric\\n    - directory path -> text files -> get_vecdb_entries() VecDBEntry entries { embedding, content, metadata } -> VecDB\\n    - querying gives VecDBQueryResult[] { content, metadata, distance }\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO\n",
    "\n",
    "Task : Create pipeline to add ml-ops-org content to Chroma vector database\n",
    "    - choose:\n",
    "        - embedding function \n",
    "        - distance metric\n",
    "    - directory path -> text files -> get_vecdb_entries() VecDBEntry entries { embedding, content, metadata } -> VecDB\n",
    "    - querying gives VecDBQueryResult[] { content, metadata, distance }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class VecDBChunk:\n",
    "    content: str\n",
    "    embedding_key: str | None = None # Optional: defaults to content\n",
    "    metadata: dict[str, Any] = field(default_factory=dict())\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.embedding_key is None:\n",
    "            self.embedding_key = self.content\n",
    "\n",
    "\n",
    "class VecDBFileChunker(ABC): \n",
    "    @abstractmethod\n",
    "    def __call__(\n",
    "        self,\n",
    "        content: str,\n",
    "        file_name: str | None = None,\n",
    "        file_path: str | None = None,\n",
    "        embedding_translation: Callable | None = None\n",
    "    ) -> list[VecDBChunk]:\n",
    "        pass\n",
    "\n",
    "class SimpleFileChunker(VecDBFileChunker):\n",
    "    def __init__(self, chunk_size: int, chunk_overlap: int):\n",
    "        # TODO: boundary checks on these\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        content: str,\n",
    "        file_name: str = \"\",\n",
    "        file_path: str = \"\",\n",
    "        embedding_translation: Callable | None = None\n",
    "    ) -> list[VecDBChunk]:\n",
    "        chunks: list[VecDBChunk] = []\n",
    "        for i in range(0, len(content), self.chunk_size):\n",
    "            start_idx = max(0, i - self.chunk_overlap)\n",
    "            end_idx = min(len(content), i + self.chunk_size + self.chunk_overlap)\n",
    "            chunks.append(VecDBChunk(\n",
    "                content=content[start_idx: end_idx],\n",
    "                metadata={\n",
    "                    \"file_name\": file_name,\n",
    "                    \"file_path\": file_path\n",
    "                }\n",
    "            ))\n",
    "        return chunks\n",
    "    \n",
    "\n",
    "def create_empty_collection(name: str, embedding_function: EmbeddingFunction, distance_metric: Literal[\"l2\", \"cosine\", \"ip\"]):\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=name)\n",
    "        print(f\"Collection: {name} already exists. deleting...\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    print(f\"creating new empty collection: {name}\")\n",
    "    return chroma_client.create_collection(\n",
    "        name=name, \n",
    "        embedding_function=embedding_function,\n",
    "        metadata={\"hnsw:space\": distance_metric}\n",
    "    )\n",
    "      \n",
    "\n",
    "def read_file_content(path: str, encoding: str = \"utf-8\"):\n",
    "    with open(path, \"r\", encoding=encoding) as f:\n",
    "     return f.read()\n",
    "    \n",
    "\n",
    "def embed_chunks_to_collection(collection: Collection, chunks: list[VecDBChunk]):\n",
    "    # TODO: handle embedding keys\n",
    "    collection.add(\n",
    "        ids=[str(uuid.uuid4()) for _ in range(len(chunks))],\n",
    "        documents=[chunk.content for chunk in chunks],\n",
    "        metadatas=[chunk.metadata for chunk in chunks]\n",
    "    )\n",
    "\n",
    "def add_directory_to_collection(dir_path: str, collection: Collection, chunker: VecDBFileChunker):\n",
    "    path = Path(dir_path)\n",
    "    for file in path.rglob(\"*.*\"):\n",
    "        file_path = str(file)\n",
    "        file_name = file.name\n",
    "        # read file content\n",
    "        content = read_file_content(file_path)\n",
    "        # chunk and embed\n",
    "        chunks = chunker(content, file_name, file_path)\n",
    "        embed_chunks_to_collection(collection, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: ml-ops-org already exists. deleting...\n",
      "creating new empty collection: ml-ops-org\n"
     ]
    }
   ],
   "source": [
    "DOCS_PATH = \"/home/ph19/dev/llm/llmops/data/ml-ops-org\"\n",
    "COLLECTION_NAME = \"ml-ops-org\"\n",
    "\n",
    "add_directory_to_collection(\n",
    "    dir_path=DOCS_PATH, \n",
    "    collection=create_empty_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=OpenAIEmbeddingFunction(),\n",
    "        distance_metric=\"l2\"\n",
    "    ), \n",
    "    chunker=SimpleFileChunker(chunk_size=1000, chunk_overlap=200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlops = chroma_client.get_collection(name=COLLECTION_NAME, embedding_function=OpenAIEmbeddingFunction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['4ceca205-c94c-4cd5-950d-380b9097ed16',\n",
       "   '02a74a11-80a2-434b-bd25-23796575b9ef',\n",
       "   'f2e68091-deb7-47bf-85a5-6d6edd53c06b',\n",
       "   '937c7447-6118-4ee4-98bf-13b5943bfd8b',\n",
       "   '275c66b1-e2ef-44d3-8991-055135454bb2',\n",
       "   'b945f078-c57f-4d7a-8657-d432ee7510d9',\n",
       "   '7aa4cf20-f2f8-4fcf-ba40-e7b01abcc642',\n",
       "   'fd680c33-38de-4883-9e23-10addd85f11a',\n",
       "   'bb83271a-6be9-496e-8a75-90ff1d59e3ef',\n",
       "   '58fbab63-90de-4304-97ed-1c808ab0097d']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['idly gaining momentum amongst Data Scientists, ML Engineers and\\n AI enthusiasts. Following this trend, the [Continuous\\n Delivery Foundation SIG MLOps](https://github.com/cdfoundation/sig-mlops) differentiates the ML models management from traditional\\n software engineering and suggests the following MLOps capabilities:\\n\\n\\n\\n\\n* MLOps aims to unify the release cycle for machine learning and software application release.\\n* MLOps enables automated testing of machine learning artifacts (e.g. data validation, ML model\\n testing, and ML model integration testing)\\n* MLOps enables the application of agile principles to machine learning projects.\\n* MLOps enables supporting machine learning models and datasets to build these models as\\n first\\\\-class citizens within CI/CD systems.\\n* MLOps reduces technical debt across machine learning models.\\n* MLOps must be a language\\\\-, framework\\\\-, platform\\\\-, and infrastructure\\\\-agnostic practice.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__Motivation.svg)\\n### Motivation for MLOps\\n\\n\\nYou will learn for what to use Machine Learning, about various scenarios of change that need to\\n be managed and the iterative nature of ML\\\\-based software development. Finally, we provide the\\n MLOps definition and show the evolution of MLOps.\\n\\n\\n\\n[Read more](/content/motivation)\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__DesigningSoftware.svg)\\n### Designing ML\\\\-powered Software\\n\\n\\nThis part is devoted t',\n",
       "   'l\\\\-world problems might be solved by applying machine learning. \\nWe established the challenges of getting the ML models into production.\\n\\n\\nFinally, we are set up to define the term **MLOps**:\\n\\n\\nThe term MLOps is defined as *“the extension of the DevOps methodology to include Machine Learning and Data Science assets as first\\\\-class citizens within the DevOps ecology”* [Source: MLOps SIG](https://github.com/cdfoundation/sig-mlops/blob/master/roadmap/2020/MLOpsRoadmap2020.md).\\n\\n\\nAlternatively, we can use the definition of **Machine Learning Engineering (MLE)**, where *MLE is the use of scientific principles, tools, and techniques of machine learning and traditional software engineering to design and build complex computing systems. MLE encompasses all stages from data collection, to model building, to make the model available for use by the product or the consumers.”* (by A.Burkov).\\n\\n\\nMLOps, like DevOps, emerges from the understanding that separating the ML model development from the process that delivers it — ML operations — lowers quality, transparency, and agility of the whole intelligent software.\\n\\n\\nThe Evolution of the MLOps\\n--------------------------\\n\\n\\nIn the early 2000s, when businesses needed to implement machine learning solutions, they used the vendors’ licensed software such as SAS, SPSS, and FICO. With the rise of open\\\\-source software and the availability of data, mor',\n",
       "   'ls are built on data, they are sensitive to the semantics, amount and completeness of incoming data.\\n\\n\\nThe second is ***model decay***: the performance of ML models in production degenerate over time because of changes in the real\\\\-life data that has not been seen during the model training.\\n\\n\\nThe third is ***locality***: when transferring ML models to new business customers, these models, which have been pre\\\\-trained on different user demographics, might not work correctly according to quality metrics.\\n\\n\\nSince ML/AI is expanding into new applications and shaping new industries, building successful ML projects remains a challenging task.\\nAs shown, there is a need to establish effective practices and processes around designing, building, and deploying ML models into production \\\\- MLOps.\\n\\n\\nFurther reading: [Why is DevOps for Machine Learning so Different?](https://hackernoon.com/why-is-devops-for-machine-learning-so-different-384z32f1)\\n\\n\\nMLOps Definition\\n----------------\\n\\n\\nWe saw what real\\\\-world problems might be solved by applying machine learning. \\nWe established the challenges of getting the ML models into production.\\n\\n\\nFinally, we are set up to define the term **MLOps**:\\n\\n\\nThe term MLOps is defined as *“the extension of the DevOps methodology to include Machine Learning and Data Science assets as first\\\\-class citizens within the DevOps ecology”* [Source: MLOps SIG](https://gi',\n",
       "   '# home.md\\n\\nURL: https://ml-ops.org/\\n\\n\\n\\n\\n\\nML Ops: Machine Learning Operations\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[![Women+ in Data/AI. A Festival for Everyone. June 30, 2023 at Radialsystem, Berlin.](/assets/ml-ops-wdai.png)](https://women-in-data-ai.tech?ref=ml-ops-org-banner)\\n\\n\\n![MLOps Logo](/assets/mlops_header_logo.svg)\\n\\n\\nMachine Learning Operations\\n===========================\\n\\n\\nWith Machine Learning Model Operationalization Management (MLOps), we\\n want\\n to provide an end\\\\-to\\\\-end machine learning development process to design, build and manage\\n reproducible, testable, and evolvable ML\\\\-powered software.\\n\\n\\n\\n\\n![MLOps Logo](/assets/mlops_visual.svg)\\n\\n\\n[![Please scroll](/assets/icons/Icon__ButtonDown.svg)](#gettingstarted)\\n\\n\\n\\n\\n\\n\\n\\nGetting started\\n---------------\\n\\n\\n\\n\\nBeing an emerging field, MLOps is rapidly gaining momentum amongst Data Scientists, ML Engineers and\\n AI enthusiasts. Following this trend, the [Continuous\\n Delivery Foundation SIG MLOps](https://github.com/cdfoundation/sig-mlops) differentiates the ML models management from traditional\\n software engineering and suggests the following MLOps capabilities:\\n\\n\\n\\n\\n* MLOps aims to unify the release cycle for machine learning and software ap',\n",
       "   'he services that consume them as part of a unified release process.”*\\nBy codifying these practices, we hope to accelerate the adoption of ML/AI in software systems and fast delivery of intelligent software.\\nIn the following, we describe a set of important concepts in MLOps such as *Iterative\\\\-Incremental Development, Automation, Continuous Deployment, Versioning, Testing, Reproducibility, and Monitoring*.\\n\\n\\nIterative\\\\-Incremental Process in MLOps\\n---------------------------------------\\n\\n\\n![Agile ML Workflow](../img/mlops-loop-en.jpg)\\n\\n\\nThe complete MLOps process includes three broad phases of *“Designing the ML\\\\-powered application”, “ML Experimentation and Development”, and “ML Operations”*.\\n\\n\\nThe first phase is devoted to *business understanding, data understanding* and *designing the ML\\\\-powered software*. In this stage, we identify our potential user, design the machine learning solution to solve its problem, and assess the further development of the project. Mostly, we would act within two categories of problems \\\\- either increasing the productivity of the user or increasing the interactivity of our application.\\n\\n\\nInitially, we define ML use\\\\-cases and prioritize them. The best practice for ML projects is to work on one ML use case at a time. Furthermore, the *design* phase aims to inspect the available data that will be needed to train our model and to specify the functio',\n",
       "   ', and for the long term. MLOps is equivalent to DevOps in software engineering: it is an extension of DevOps for the design, development, and sustainable deployment of ML models in software systems. Model Governance encompasses a set of processes and frameworks that help in the deployment of ML. Setting up automatized and reproducible data and ML pipelines reduces the amount of time required to bring models into production (time\\\\-to\\\\-market). There are six interactive phases in the ML development process:\\n\\n\\n* Business and Data Understanding\\n* Data Engineering\\n* Model Engineering\\n* Quality Assurance for ML Systems\\n* Deployment\\n* Monitoring and Maintenance\\n\\n\\nThis figure shows the most important phases of the ML life cycle according to [CRISP\\\\-ML(Q)](https://arxiv.org/pdf/2003.05155.pdf):\\n\\n\\n![CRISP-ML(Q) Process](../img/crisp-ml-process.jpg)\\nFig. 1: CRISP\\\\-ML(Q) process model\\n\\n\\nHowever, the operationalization of ML models is not the only challenge many companies are facing today. The use of MLobliges companies responsibility and compliance with legal requirements. To fulfill these obligations, a company requires processes through which it is able to:\\n\\n\\n* control access to ML models\\n* put guidelines and legal requirements into practice\\n* track interactions with the ML models and their results\\n* document the foundation of an ML model (stakeholders, business context, training data, f',\n",
       "   'ess that delivers it — ML operations — lowers quality, transparency, and agility of the whole intelligent software.\\n\\n\\nThe Evolution of the MLOps\\n--------------------------\\n\\n\\nIn the early 2000s, when businesses needed to implement machine learning solutions, they used the vendors’ licensed software such as SAS, SPSS, and FICO. With the rise of open\\\\-source software and the availability of data, more software practitioners started using Python or R libraries for training ML models. However, the usage of the models in production was still a problem. As the containerization technology was emerging, the deployment of the model in a scalable way was solved by using Docker containers and Kubernetes. Recently, we see the evolution of those solutions into ML deployment platforms that cover the whole iteration of model experimentation, training, deployment, and monitoring. The following Figure visualizes the evolution of the MLOps.\\n\\n\\n![The Evolution of MLOps](../img/mlops-evolution.jpg)\\n\\n\\n\\n\\n\\nThe content of this site was created by Dr. Larysa Visengeriyeva, Anja Kammer, Isabel Bär,\\n Alexander Kniesz, and Michael Plöd (DDD Advisor). Design made by Sebastian Eberstaller.\\n\\n\\nIt is published under [Creative\\n Commons Attribution 4\\\\.0 International Public License](https://creativecommons.org/licenses/by/4.0/) and can therefore be shared and adapted\\n with attribution (\"INNOQ\").\\n\\n\\nMade and maintai',\n",
       "   'ver a stable quality ML model that we will run in production.\\n\\n\\nThe main focus of the *“ML Operations”* phase is to deliver the previously developed ML model in production by using established DevOps practices such as testing, versioning, continuous delivery, and monitoring.\\n\\n\\nAll three phases are interconnected and influence each other. For example, the design decision during the design stage will propagate into the experimentation phase and finally influence the deployment options during the final operations phase.\\n\\n\\nAutomation\\n----------\\n\\n\\nThe level of automation of the Data, ML Model, and Code pipelines determines the maturity of the ML process. \\nWith increased maturity, the velocity for the training of new models is also increased.\\nThe objective of an MLOps team is to automate the deployment of ML models into the core software system or as a service component.\\nThis means, to automate the complete ML\\\\-workflow steps without any manual intervention.\\nTriggers for automated model training and deployment can be calendar events, messaging, monitoring events, as well as changes on data, model training code, and application code.\\n\\n\\nAutomated testing helps discovering problems quickly and in early stages.\\nThis enables fast fixing of errors and learning from mistakes.\\n\\n\\nTo adopt MLOps, we see *three levels of automation*, starting from the initial level with manual model training an',\n",
       "   '# mlops-principles.md\\n\\nURL: https://ml-ops.org/content/mlops-principles\\n\\n\\n\\n\\n\\nMLOps Principles\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![MLOps Logo](/assets/mlops_header_logo.svg)\\n[Back](/)\\n\\n\\n\\n\\n\\n![Icon](/assets/icons/Icon__Principles.svg)\\n\\n\\nMLOps Principles\\n================\\n\\n\\nAs machine learning and AI propagate in software products and services, we need to establish best practices and tools to test, deploy, manage, and monitor ML models in real\\\\-world production. In short, with MLOps we strive to avoid *“technical debt”* in machine learning applications.\\n\\n\\nSIG MLOps defines *“an optimal MLOps experience \\\\[as] one where Machine Learning assets are treated consistently with all other software assets within a CI/CD environment. Machine Learning models can be deployed alongside the services that wrap them and the services that consume them as part of a unified release process.”*\\nBy codifying these practices, we hope to accelerate the adoption of ML/AI in software systems and fast delivery of intelligent software.\\nIn the following, we describe a set of important concepts in MLOps such as *Iterative\\\\-Incremental Development, Automation, Continuous Deployment, Versioning, Testing, Reproducibility, and Moni',\n",
       "   'r MLOps\\n\\n\\nYou will learn for what to use Machine Learning, about various scenarios of change that need to\\n be managed and the iterative nature of ML\\\\-based software development. Finally, we provide the\\n MLOps definition and show the evolution of MLOps.\\n\\n\\n\\n[Read more](/content/motivation)\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__DesigningSoftware.svg)\\n### Designing ML\\\\-powered Software\\n\\n\\nThis part is devoted to one of the most important phase in any software project — understanding\\n the business problem and requirements. As these equally apply to ML\\\\-based software you need to\\n make sure to have a good understanding before setting out designing things.\\n\\n\\n\\n[Read more](/content/phase-zero)\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__Lifecycle.svg)\\n### End\\\\-to\\\\-End ML Workflow Lifecycle\\n\\n\\nIn this section, we provide a high\\\\-level overview of a typical workflow for machine\\n learning\\\\-based software development.\\n\\n\\n\\n[Read more](/content/end-to-end-ml-workflow)\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__ThreeLevels.svg)\\n### Three Levels of ML\\\\-based Software\\n\\n\\nYou will learn about three core elements of ML\\\\-based software — Data, ML models, and Code. In\\n particular, we will talk about\\n\\n\\n* Data Engineering Pipelines\\n* ML Pipelines and ML workflows.\\n* Model Serving Patterns and Deployment Strategies\\n\\n\\n\\n[Read more](/content/three-levels-of-ml-software)\\n\\n\\n\\n\\n\\n![](/assets/icons/Icon__Principles.svg)\\n### MLOps Principles\\n\\n\\nIn this p']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'file_name': 'home.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/home.md'},\n",
       "   {'file_name': 'motivation.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/motivation.md'},\n",
       "   {'file_name': 'motivation.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/motivation.md'},\n",
       "   {'file_name': 'home.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/home.md'},\n",
       "   {'file_name': 'mlops-principles.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/mlops-principles.md'},\n",
       "   {'file_name': 'model-governance.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/model-governance.md'},\n",
       "   {'file_name': 'motivation.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/motivation.md'},\n",
       "   {'file_name': 'mlops-principles.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/mlops-principles.md'},\n",
       "   {'file_name': 'mlops-principles.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/content/mlops-principles.md'},\n",
       "   {'file_name': 'home.md',\n",
       "    'file_path': '/home/ph19/dev/llm/llmops/data/ml-ops-org/home.md'}]],\n",
       " 'distances': [[0.4291542172431946,\n",
       "   0.5055168762759867,\n",
       "   0.5519158828087244,\n",
       "   0.5652387738227844,\n",
       "   0.6140013933181763,\n",
       "   0.6261250376701355,\n",
       "   0.6449233836856563,\n",
       "   0.6921581029891968,\n",
       "   0.7001899480819702,\n",
       "   0.7062638998031616]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlops.query(query_texts=[\n",
    "    \"\"\"Getting started\n",
    "Being an emerging field, MLOps is rapidly gaining momentum amongst Data Scientists, ML Engineers and AI enthusiasts. Following this trend, the Continuous Delivery Foundation SIG MLOps differentiates the ML models management from traditional software engineering and suggests the following MLOps capabilities:\"\"\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
